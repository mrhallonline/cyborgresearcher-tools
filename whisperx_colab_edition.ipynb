{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0e80c681",
   "metadata": {},
   "source": [
    "# üß† WhisperX Transcription + Diarization for Qual Researchers (Colab Edition)\n",
    "This notebook transcribes and diarizes audio using WhisperX and pyannote. It's designed for **education researchers** and others analyzing interview or classroom audio. No setup beyond this notebook is required."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cda4355",
   "metadata": {},
   "source": [
    "## üîß Step 1: Install Required Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ad77eed",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q git+https://github.com/m-bain/whisperx.git\n",
    "!pip install -q speechbrain torch torchvision torchaudio\n",
    "!pip install -q pandas nltk webvtt-py srt python-dotenv ipywidgets plotly"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a093ea86",
   "metadata": {},
   "source": [
    "## üîê Step 2: Enter Hugging Face Token (Required for Diarization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d6f21fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "HF_TOKEN = input(\"Paste your Hugging Face token here: \")\n",
    "os.environ['HF_TOKEN'] = HF_TOKEN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e67d80e",
   "metadata": {},
   "source": [
    "## üìÅ Step 3: Upload Your Audio and (Optional) Pseudonym CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40a01449",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "uploaded = files.upload()\n",
    "audio_file_path = next(iter(uploaded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f4d2b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import whisperx\n",
    "import torch\n",
    "import pandas as pd\n",
    "\n",
    "# Set device\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "compute_type = \"float16\" if device == \"cuda\" else \"float32\"\n",
    "\n",
    "# Load and transcribe\n",
    "model = whisperx.load_model(\"large-v2\", device, compute_type=compute_type)\n",
    "transcription = model.transcribe(audio_file_path)\n",
    "\n",
    "# Align with WhisperX\n",
    "model_a, metadata = whisperx.load_align_model(\n",
    "    language_code=transcription[\"language\"], device=device)\n",
    "result_aligned = whisperx.align(transcription[\"segments\"], model_a, metadata, audio_file_path, device)\n",
    "\n",
    "# Apply diarization\n",
    "diarize_model = whisperx.DiarizationPipeline(use_auth_token=HF_TOKEN, device=device)\n",
    "segments = diarize_model(audio_file_path)\n",
    "\n",
    "# Assign speaker labels\n",
    "result_with_speakers = whisperx.assign_word_speakers(\n",
    "    diarize_model, result_aligned, segments)\n",
    "\n",
    "# Convert to DataFrame\n",
    "df = pd.DataFrame(result_with_speakers[\"segments\"])\n",
    "df.to_csv(\"transcript_output.csv\", index=False)\n",
    "df[[\"start\", \"end\", \"text\", \"speaker\"]].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88a29a2f",
   "metadata": {},
   "source": [
    "## ‚úÖ Step 4: Download Your Transcription"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "573280b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "files.download(\"transcript_output.csv\")"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
