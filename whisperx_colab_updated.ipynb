{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f9800359",
   "metadata": {},
   "source": [
    "# 🧠 WhisperX + PyAnnote Diarization (Colab Edition)\n",
    "This notebook transcribes audio using WhisperX, then applies speaker diarization using the latest version of `pyannote.audio`. Built for qualitative researchers.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37ec9eb1",
   "metadata": {},
   "source": [
    "## 🔧 Step 1: Install Required Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "851fcfa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q git+https://github.com/m-bain/whisperx.git\n",
    "!pip install -q pyannote.audio --upgrade\n",
    "!pip install -q torch torchvision torchaudio\n",
    "!pip install -q pandas ipywidgets plotly"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a912631",
   "metadata": {},
   "source": [
    "## 🔐 Step 2: Enter Hugging Face Token (for diarization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f98a610",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "HF_TOKEN = input(\"Paste your Hugging Face token here: \")\n",
    "os.environ['HF_TOKEN'] = HF_TOKEN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "487ad1c9",
   "metadata": {},
   "source": [
    "## 📁 Step 3: Upload Audio File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd22b4ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "uploaded = files.upload()\n",
    "audio_file_path = next(iter(uploaded))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7096149c",
   "metadata": {},
   "source": [
    "## 📝 Step 4: Transcribe Audio Using WhisperX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53f90efe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import whisperx\n",
    "import torch\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "model = whisperx.load_model('large-v2', device)\n",
    "transcription = model.transcribe(audio_file_path)\n",
    "\n",
    "align_model, metadata = whisperx.load_align_model(\n",
    "    language_code=transcription['language'], device=device)\n",
    "aligned_result = whisperx.align(transcription['segments'], align_model, metadata, audio_file_path, device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10744f7b",
   "metadata": {},
   "source": [
    "## 🗣️ Step 5: Perform Speaker Diarization with pyannote.audio 3.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "895abc16",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyannote.audio import Pipeline\n",
    "\n",
    "pipeline = Pipeline.from_pretrained('pyannote/speaker-diarization', use_auth_token=HF_TOKEN)\n",
    "diarization = pipeline(audio_file_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f65cb75a",
   "metadata": {},
   "source": [
    "## 🔗 Step 6: Assign Speakers to Words by Timestamp Overlap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c697e22",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Convert word segments to DataFrame\n",
    "words = aligned_result['word_segments']\n",
    "word_df = pd.DataFrame(words)\n",
    "\n",
    "# Assign speaker to each word\n",
    "word_df['speaker'] = 'UNKNOWN'\n",
    "for turn in diarization.itertracks(yield_label=True):\n",
    "    segment, _, speaker = turn\n",
    "    mask = (word_df['start'] >= segment.start) & (word_df['end'] <= segment.end)\n",
    "    word_df.loc[mask, 'speaker'] = speaker\n",
    "\n",
    "# Save CSV\n",
    "word_df.to_csv(\"transcript_with_speakers.csv\", index=False)\n",
    "word_df[['start', 'end', 'word', 'speaker']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb169985",
   "metadata": {},
   "source": [
    "## ✅ Step 7: Download Your Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "770ce6e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "files.download(\"transcript_with_speakers.csv\")"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
